Model class:
    * Parse one type of model.
    * No entanglement with output and runs, just the model definition
    * Detection of model type. Different model parsers invoked.
    * Model class is model agnostic but actual NMTRANControlStream, PharmML etc are not. APIs are model specific

APIs on models:
    * API is model agnostic, implementation is not. Duck typing here.
    * APIs could be Input to set file and columns, Parameters, Transformations etc
    * APIs are abstract concepts like operations on models.
    * Why multiple APIs in a hierarchy and not only one directly on the model class?
        * Compare code: 
            model = Model("run1.mod")
            model.input.column_list()       or model.column_list()
        * Get initial estimates:
            model.parameters.initial_estimates()
    * API methods will use lower level API provided by the model class itself

Data Class:
    * One central dataset storage implementation. Different interpretations of different columns are needed like EVID, AMT etc

Output Class:
    * Read in one type of output and convert to SO or other standardised output storage.

Run environment: Is the cluster or local or OS etc to start jobs on

Run command: The actual command to start a job, like nmfe or nmqual for NONMEM

The directories: Run directory, invoking directory, where are the models? Which files to copy where? Organization of files.

Tool: A bundle of operations. Organizes a run with standard files generated lika meta.yaml
